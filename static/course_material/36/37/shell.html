
<br/><br/>
<p>

<p>
<font face="symbol"></font
> <b>Unix Shell Programming</b>

<p>
<b>[This topic may be in week 1, week 4, or week 11 depending on the holidays
each semester.]</b>

<p>
Sometimes the best way to solve a programming problem is not to write a
program at all, but instead to glue together existing programs that
solve the problem.

<p>
As an example, we'll construct a spelling-checker program.  It will take
a text file as input, and will generate a list of words that are in the
file but not in the online dictionary.

<p>
For this demonstration I'll use the file named <tt>summary</tt> as the
text I want to spell-check.

<p>
We are given a file that contains several words per line, including
things we don't want to compare against the dictionary, such as spaces
and punctuation.  Our job will be easier if we transform the input
into a file with exactly one word per line, with no spaces or
punctuation (except that we'll keep apostrophes, which are part of
words - contractions such as "we'll" - rather than word
delimiters).

<p>
<tt>  <pre>tr -d '.,;:"'134!'134[]()' &lt; summary &#62; nopunct

</pre></tt>

<p>
<tt>Tr</tt> is a Unix utility program that translates one character into
another.  In this case, because of the <tt>-d</tt> switch, we are asking
it to delete from the input any periods, commas, semicolons, colons,
exclamation points, braces, and parentheses.

<p>
The single-quote (<tt>'</tt>) characters are used to tell the shell
that the characters between them should not be interpreted according
to the shell's usual syntax.  For example, a semicolon in a shell
command line separates two distinct commands; the shell does one
and then does the other.  Here we want the semicolon to be passed to
the <tt>tr</tt> program just as if it were a letter of the alphabet.

<p>
When a program asks to read or print text, without specifying a
particular source or destination, its input comes from something
called the <i>standard input </i>; its output goes to the
<i>standard output.</i>  Ordinarily, the standard input is the
keyboard and the standard output is the screen.  But you can
<i>redirect </i> them using the characters <tt>&lt;</tt> and <tt>&#62;</tt> in
shell commands.  In this case, we are asking the shell to connect
<tt>tr</tt>'s standard input to the file named <tt>summary</tt>, and to
connect its standard output to a new file named <tt>nopunct</tt>.

<p>
Spacing characters in text files include the space character and
the tab character.  To simplify things, let's translate tabs to
spaces.

<p>
<tt>  <pre>tr '    ' ' ' &lt; nopunct &#62; notab

</pre></tt>

<p>
Between the first pair of single-quotes is a tab character.  <tt>Tr</tt>
will translate every tab in the file to a space.

<p>
We really want one word per line, so let's translate spaces to
newline characters.

<p>
<tt>  <pre>tr ' ' ''134n' &lt; notab &#62; oneword

</pre></tt>

<p>
The notation <tt>'134n</tt> is a standard Unix notation for
the newline character.

<p>
In English text, we capitalize the first word of each sentence.
The words in the dictionary aren't capitalized (unless they're
proper nouns).  So let's translate capital letters to lower case:

<p>
<tt>  <pre>tr '[A-Z]' '[a-z]' &lt; oneword &#62; lowcase

</pre></tt>

<p>
The notation <tt>[A-Z]</tt> means all the characters between the given
extremes; it's equivalent to

<p>
<tt>  <pre>ABCDEFGHIJKLMNOPQRSTUVWXYZ

</pre></tt>

<p>
What <tt>tr</tt> does is convert every instance of the nth character of its
first argument into the nth character of the second argument.  So we are
asking it to convert <tt>A</tt> to <tt>a</tt>, <tt>B</tt> to <tt>b</tt>, and so on.

<p>

<p>
Our plan is to compare each word of the text against the words in
the dictionary.  But we don't have to read every word of the
dictionary for each word of the file; since the dictionary is
sorted alphabetically, if we sort the words in our text file, we
can just make one pass through both files in parallel.

<p>
<tt>  <pre>sort &lt; lowcase &#62; sorted

</pre></tt>

<p>
The <tt>sort</tt> program can take arguments to do sorting in many
different ways; for example, you can ask it to sort the lines of
a file based on the third word of each line.  But in this case,
we want the simplest possible sort: The "sort key" is the entire
line, and we're sorting in character-code order (which is the same
as alphabetical order since we eliminated capital letters).

<p>
Common words like "the" will occur many times in our text.  There's
no need to spell-check the same word repeatedly.  Since we've sorted
the file, all instances of the same word are next to each other in
the file, so we can ask Unix to eliminate consecutive equal lines:

<p>
<tt>  <pre>uniq &lt; sorted &#62; nodup

</pre></tt>

<p>
<tt>Uniq</tt> has that name because in its output file every line is
unique; it eliminates (consecutive) duplicates.

<p>
Now we're ready to compare our file against the dictionary.  This may
seem like a special-purpose operation for which we'll finally have to
write our own program, but in fact what we want to do is a common
database operation, combining entries from two different databases
that have a certain element in common.  Our application is a trivial
one in which each "database" entry has only one element, and we are
just checking for matches.

<p>
This combining of databases is called a <i>join </i> in the technical
terminology of database programming.  In our case, what we want is not
the join itself, but rather a report of those elements of one database
(our text file) that don't occur in the other database (the online
dictionary).  This is what the <tt>-v1</tt> switch means:

<p>
<tt>  <pre>join -v1 nodup words &#62; errors

</pre></tt>

<p>
That's it!  We now have a list of misspelled words that we can correct
in Emacs.  The user interface of this spelling program isn't fancy, but
it gets the job done, and we didn't have to work hard to get it.

<p>
It's a little ugly that we've created all these intermediate files.
But we don't have to, because the shell includes a "pipe" feature that
lets you connect the standard output of one program to the standard
input of another.  So we can do it this way:

<p>
<tt>  <pre>tr -d '.,;:"'134!'134[]()'  -  tr '    ' ' '  -  tr ' ' ''134n' '134
 -  tr '[A-Z]' '[a-z]'  -  sort  -  uniq  -  join -v1 - words

</pre></tt>

<p>
The backslash at the end of the first line is the shell's <i>continuation </i>
character, telling it that the same command continues on the next line.
The minus sign (<tt>-</tt>) as the second argument to <tt>join</tt> tells it to
take its first database input from its standard input rather than from a
named file.  (This is a standard Unix convention for programs that read
more than one input file.)

<p>
We can write a file named <tt>spell</tt> containing this command line, mark
the file as executable (a program, rather than data) with the command

<p>
<tt>  <pre>chmod +x spell

</pre></tt>

<p>
and then instead of the sequence of commands I used earlier we can
just say

<p>
<tt>  <pre>spell &lt; summary &#62; errors

</pre></tt>

<p>
What we've done is use existing programs, glued together in a "scripting
language" (the Unix shell), to solve a new problem with very little effort.
This is called "code re-use."  The huge collection of Unix utility programs
have been written with this technique in mind; that's why almost all of them
are what the Unix designers call "filters," meaning programs that take a
text stream as input and produce a modified text stream as output.  Each
filter doesn't care where its input and output are; they can be files, or
they can be pipes connected to another filter program.

<p>

<p>
